import cv2
import dlib
import numpy as np
import os
import re
from hashlib import md5
from scipy.spatial import distance as dist
from skimage.metrics import structural_similarity as ssim
from collections import defaultdict

# **ç›®å½•è®¾ç½®**
input_folder = "H:/fenjie/finspt"   # è¾“å…¥æ–‡ä»¶å¤¹
output_folder = "H:/fenjie/tp"      # è¾“å‡ºæ–‡ä»¶å¤¹
os.makedirs(output_folder, exist_ok=True)

# **åŠ è½½ Dlib äººè„¸æ£€æµ‹å™¨ & 68 å…³é”®ç‚¹é¢„æµ‹å™¨**
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("E:/ai/fenjie/shape_predictor_68_face_landmarks.dat")

# **å‚æ•°è®¾ç½®ï¼ˆé€‚å½“æ”¾å®½é™åˆ¶ï¼Œæé«˜æ£€æµ‹ç‡ï¼‰**
blur_threshold = 50  # é™ä½æ¨¡ç³Šé˜ˆå€¼ï¼ˆLaplacian å˜æ¢å€¼è¶Šé«˜è¶Šæ¸…æ™°ï¼‰
yaw_threshold = 60  # å·¦å³åå¤´æœ€å¤§è§’åº¦ï¼ˆè¶Šå¤§è¶Šå®½æ¾ï¼‰
pitch_threshold = 60  # ä¸Šä¸‹ä¿¯ä»°æœ€å¤§è§’åº¦ï¼ˆè¶Šå¤§è¶Šå®½æ¾ï¼‰
eye_aspect_ratio_threshold = 0.3  # çœ¼ç›é—­åˆé˜ˆå€¼ï¼ˆé€‚å½“æ”¾å®½ï¼‰
similarity_threshold = 0.8  # å›¾ç‰‡ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0~1ï¼Œè¶Šä½è¶Šä¸¥æ ¼ï¼‰

# **ç»Ÿè®¡æ•°æ®**
total_images = 0
kept_images = 0
removed_images = 0
removal_reasons = defaultdict(int)  # è®°å½•å»é™¤åŸå› 

# **ç”¨äºå­˜å‚¨å·²å¤„ç†å›¾ç‰‡çš„å“ˆå¸Œå€¼**
processed_hashes = set()

def extract_prefix(filename):
    """ æå–æ–‡ä»¶åå‰ç¼€ï¼ˆå¦‚ 1_frame_00030 -> 1ï¼‰"""
    match = re.match(r"(\d+)_frame_\d+", filename)
    return match.group(1) if match else None

def calculate_blur(image):
    """ è®¡ç®—å›¾åƒçš„æ¸…æ™°åº¦ï¼ˆLaplacian å˜æ¢ï¼‰"""
    return cv2.Laplacian(image, cv2.CV_64F).var()

def eye_aspect_ratio(eye):
    """ è®¡ç®—çœ¼ç›çºµæ¨ªæ¯”ï¼ˆEARï¼‰ï¼Œç”¨äºæ£€æµ‹é—­çœ¼ """
    A = dist.euclidean(eye[1], eye[5])
    B = dist.euclidean(eye[2], eye[4])
    C = dist.euclidean(eye[0], eye[3])
    return (A + B) / (2.0 * C)

def is_face_angle_valid(landmarks):
    """ åˆ¤æ–­äººè„¸è§’åº¦æ˜¯å¦ç¬¦åˆè¦æ±‚ """
    nose = landmarks[30]     # é¼»å°–
    left_eye = landmarks[36]  # å·¦çœ¼è§’
    right_eye = landmarks[45]  # å³çœ¼è§’
    chin = landmarks[8]       # ä¸‹å·´

    # è®¡ç®— Yawï¼ˆå·¦å³åå¤´è§’åº¦ï¼‰
    delta_x = right_eye[0] - left_eye[0]
    delta_y = right_eye[1] - left_eye[1]
    yaw = np.degrees(np.arctan2(delta_y, delta_x))

    # è®¡ç®— Pitchï¼ˆä¸Šä¸‹ä½å¤´ä»°å¤´è§’åº¦ï¼‰
    delta_nose = nose[1] - chin[1]
    delta_eyes = np.linalg.norm(right_eye - left_eye)
    pitch = np.degrees(np.arctan2(delta_nose, delta_eyes))

    return abs(yaw) <= yaw_threshold and abs(pitch) <= pitch_threshold

def dhash(image, size=8):
    """ è®¡ç®—å›¾åƒçš„ dHashï¼ˆæ„ŸçŸ¥å“ˆå¸Œï¼‰ï¼Œç”¨äºæ£€æµ‹ç›¸ä¼¼å›¾ç‰‡ """
    resized = cv2.resize(image, (size + 1, size))
    diff = resized[:, 1:] > resized[:, :-1]
    return sum([2 ** i for (i, v) in enumerate(diff.flatten()) if v])

def hash_histogram(hist):
    """ è®¡ç®—ç›´æ–¹å›¾çš„ MD5 å“ˆå¸Œ """
    return md5(hist.tobytes()).hexdigest()

def is_similar(image, img_hist):
    """ åˆ¤æ–­å›¾ç‰‡æ˜¯å¦ä¸å·²å¤„ç†å›¾ç‰‡ç›¸ä¼¼ """
    img_dhash = dhash(image)
    img_hist_hash = hash_histogram(img_hist)

    if img_dhash in processed_hashes or img_hist_hash in processed_hashes:
        return True  # è¯´æ˜å·²ç»æœ‰ç›¸ä¼¼å›¾ç‰‡
    return False

# **å¤„ç†æ¯å¼ å›¾ç‰‡**
for filename in os.listdir(input_folder):
    img_path = os.path.join(input_folder, filename)
    image = cv2.imread(img_path)

    if image is None:
        continue

    total_images += 1

    # **è·å–å‰ç¼€**
    prefix = extract_prefix(filename)
    if prefix is None:
        removed_images += 1
        removal_reasons["æ–‡ä»¶åä¸ç¬¦åˆè§„åˆ™"] += 1
        continue  # æ²¡æœ‰åŒ¹é…åˆ°å‰ç¼€çš„æ–‡ä»¶è·³è¿‡

    # **è½¬æ¢ä¸ºç°åº¦å›¾**
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # **1. æ¸…æ™°åº¦æ£€æµ‹**
    blur_value = calculate_blur(gray)
    if blur_value < blur_threshold:
        removed_images += 1
        removal_reasons["å›¾ç‰‡è¿‡äºæ¨¡ç³Š"] += 1
        continue  # è¿‡äºæ¨¡ç³Šï¼Œè·³è¿‡

    # **2. äººè„¸æ£€æµ‹**
    faces = detector(gray)

    if len(faces) == 0:
        removed_images += 1
        removal_reasons["æœªæ£€æµ‹åˆ°äººè„¸"] += 1
        continue  # æ²¡æ£€æµ‹åˆ°äººè„¸ï¼Œç›´æ¥èˆå¼ƒ

    # **3. éå†æ‰€æœ‰æ£€æµ‹åˆ°çš„äººè„¸**
    face_ok = False
    for face in faces:
        landmarks = predictor(gray, face)
        landmarks = np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(68)])

        # **4. çœ¼ç›é—­åˆæ£€æµ‹**
        left_eye = landmarks[36:42]
        right_eye = landmarks[42:48]
        ear_left = eye_aspect_ratio(left_eye)
        ear_right = eye_aspect_ratio(right_eye)

        if ear_left < eye_aspect_ratio_threshold and ear_right < eye_aspect_ratio_threshold:
            removal_reasons["çœ¼ç›é—­åˆ"] += 1
            continue  # çœ¼ç›é—­åˆï¼Œè·³è¿‡

        # **5. å¤´éƒ¨è§’åº¦æ£€æµ‹**
        if not is_face_angle_valid(landmarks):
            removal_reasons["å¤´éƒ¨è§’åº¦ä¸ç¬¦åˆè¦æ±‚"] += 1
            continue  # å¤´éƒ¨è§’åº¦ä¸ç¬¦åˆè¦æ±‚ï¼Œè·³è¿‡

        face_ok = True
        break  # åªè¦æœ‰ä¸€ä¸ªåˆæ ¼çš„äººè„¸ï¼Œå°±ä¿ç•™

    if face_ok:
        # **6. ç›¸ä¼¼åº¦æ£€æµ‹**
        img_hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
        img_hist = cv2.normalize(img_hist, img_hist).flatten()

        if is_similar(gray, img_hist):
            removed_images += 1
            removal_reasons["å›¾ç‰‡è¿‡äºç›¸ä¼¼"] += 1
            continue

        # **å­˜å…¥å·²å¤„ç†å›¾ç‰‡çš„å“ˆå¸Œ**
        processed_hashes.add(dhash(gray))
        processed_hashes.add(hash_histogram(img_hist))

        # **ä¿å­˜å½“å‰å›¾ç‰‡**
        cv2.imwrite(os.path.join(output_folder, filename), image)
        kept_images += 1
    else:
        removed_images += 1

# **ç»Ÿè®¡ç»“æœ**
print(f"ğŸ“· æ€»å…±å¤„ç†å›¾ç‰‡: {total_images}")
print(f"âœ… ä¿ç•™å›¾ç‰‡: {kept_images}")
print(f"âŒ å»é™¤å›¾ç‰‡: {removed_images}")
print("\nğŸ“Š **å»é™¤åŸå› ç»Ÿè®¡**:")
for reason, count in removal_reasons.items():
    print(f"  - {reason}: {count} å¼ ")





# import cv2
# import dlib
# import numpy as np
# import os
# import re
# from scipy.spatial import distance as dist
# from skimage.metrics import structural_similarity as ssim
# from collections import defaultdict
#
# # ç›®å½•è®¾ç½®
# input_folder = "H:/fenjie/finspt"   # è¾“å…¥æ–‡ä»¶å¤¹
# output_folder = "H:/fenjie/tp"      # è¾“å‡ºæ–‡ä»¶å¤¹
# os.makedirs(output_folder, exist_ok=True)
#
# # åŠ è½½ Dlib äººè„¸æ£€æµ‹å™¨ & 68 å…³é”®ç‚¹é¢„æµ‹å™¨
# detector = dlib.get_frontal_face_detector()
# predictor = dlib.shape_predictor("E:/ai/fenjie/shape_predictor_68_face_landmarks.dat")
#
# # å‚æ•°è®¾ç½®
# blur_threshold = 30  # æ¸…æ™°åº¦é˜ˆå€¼ï¼ˆè¶Šé«˜è¶Šä¸¥æ ¼ï¼‰
# yaw_threshold = 50     # å·¦å³åå¤´æœ€å¤§è§’åº¦ï¼ˆæ”¹ä¸º 30Â° ä»¥å†…ï¼‰
# pitch_threshold = 50   # ä¸Šä¸‹ä¿¯ä»°æœ€å¤§è§’åº¦
# eye_aspect_ratio_threshold = 0.25  # çœ¼ç›é—­åˆé˜ˆå€¼ï¼ˆè¶Šä½è¶Šä¸¥æ ¼ï¼‰
# similarity_threshold = 0.8  # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆè¶Šä½è¶Šä¸¥æ ¼ï¼‰
#
# # è®°å½•æœ€ä½³å›¾ç‰‡ï¼ˆæŒ‰å‰ç¼€åˆ†ç»„ï¼‰
# best_images = defaultdict(lambda: None)
# best_image_ssim = defaultdict(lambda: -1)
#
# # ç»Ÿè®¡æ•°æ®
# total_images = 0
# kept_images = 0
# removed_images = 0
# removal_reasons = defaultdict(int)  # è®°å½•å»é™¤åŸå› çš„ç»Ÿè®¡
#
# def extract_prefix(filename):
#     """ æå–æ–‡ä»¶åå‰ç¼€ï¼ˆå¦‚ 1_frame_00030 -> 1ï¼‰"""
#     match = re.match(r"(\d+)_frame_\d+", filename)
#     return match.group(1) if match else None
#
# def calculate_blur(image):
#     """ è®¡ç®—å›¾åƒçš„æ¸…æ™°åº¦ï¼ˆLaplacian æ¨¡ç³Šåº¦ï¼‰"""
#     return cv2.Laplacian(image, cv2.CV_64F).var()
#
# def eye_aspect_ratio(eye):
#     """ è®¡ç®—çœ¼ç›çºµæ¨ªæ¯”ï¼ˆEARï¼‰ï¼Œç”¨äºæ£€æµ‹é—­çœ¼ """
#     A = dist.euclidean(eye[1], eye[5])
#     B = dist.euclidean(eye[2], eye[4])
#     C = dist.euclidean(eye[0], eye[3])
#     return (A + B) / (2.0 * C)
#
# def face_orientation(landmarks):
#     """ è®¡ç®—é¢éƒ¨åèˆªè§’ï¼ˆYawï¼‰å’Œä¿¯ä»°è§’ï¼ˆPitchï¼‰"""
#     # å…³é”®ç‚¹ç´¢å¼•ï¼š
#     left_eye = landmarks[36:42]
#     right_eye = landmarks[42:48]
#     nose = landmarks[27]  # é¼»æ¢
#     chin = landmarks[8]   # ä¸‹å·´
#     left_cheek = landmarks[0]  # å·¦è„¸é¢Š
#     right_cheek = landmarks[16]  # å³è„¸é¢Š
#
#     # è®¡ç®—åèˆªè§’ï¼ˆYawï¼‰: å·¦å³åå¤´è§’åº¦
#     yaw = abs(right_cheek[0] - left_cheek[0]) / abs(nose[0] - chin[0]) * 100
#
#     # è®¡ç®—ä¿¯ä»°è§’ï¼ˆPitchï¼‰ï¼šä¸Šä¸‹åå¤´è§’åº¦
#     pitch = abs(nose[1] - chin[1]) / abs(left_eye[1] - right_eye[1]) * 100
#
#     return yaw, pitch
#
# def compare_images(image1, image2):
#     """ æ¯”è¾ƒä¸¤å¼ å›¾ç‰‡çš„ç›¸ä¼¼åº¦ï¼Œç¡®ä¿å°ºå¯¸ä¸€è‡´ """
#     gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)
#     gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)
#
#     # ç»Ÿä¸€å°ºå¯¸ï¼Œé¿å…å°ºå¯¸ä¸åŒ¹é…
#     h, w = gray1.shape
#     gray2 = cv2.resize(gray2, (w, h))
#
#     score, _ = ssim(gray1, gray2, full=True)
#     return score
#
# # å¤„ç†æ¯å¼ å›¾ç‰‡
# for filename in os.listdir(input_folder):
#     img_path = os.path.join(input_folder, filename)
#     image = cv2.imread(img_path)
#
#     if image is None:
#         removal_reasons["æ— æ³•è¯»å–å›¾åƒ"] += 1
#         continue
#
#     total_images += 1
#
#     # **è·å–å‰ç¼€**
#     prefix = extract_prefix(filename)
#     if prefix is None:
#         removal_reasons["æ— æ•ˆçš„æ–‡ä»¶åå‰ç¼€"] += 1
#         removed_images += 1
#         continue  # æ²¡æœ‰åŒ¹é…åˆ°å‰ç¼€çš„æ–‡ä»¶è·³è¿‡
#
#     # è½¬æ¢ä¸ºç°åº¦å›¾
#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
#
#     # 1. æ¸…æ™°åº¦æ£€æµ‹
#     blur_value = calculate_blur(gray)
#     if blur_value < blur_threshold:
#         removal_reasons["å›¾åƒè¿‡äºæ¨¡ç³Š"] += 1
#         removed_images += 1
#         continue  # è¿‡äºæ¨¡ç³Šï¼Œè·³è¿‡
#
#     # 2. äººè„¸æ£€æµ‹
#     faces = detector(gray)
#     if len(faces) == 0:
#         removal_reasons["æœªæ£€æµ‹åˆ°äººè„¸"] += 1
#         removed_images += 1
#         continue  # æ²¡æ£€æµ‹åˆ°äººè„¸ï¼Œè·³è¿‡
#
#     # 3. éå†æ‰€æœ‰æ£€æµ‹åˆ°çš„äººè„¸
#     face_ok = False
#     for face in faces:
#         landmarks = predictor(gray, face)
#         if landmarks is None:
#             continue  # å…³é”®ç‚¹æ£€æµ‹å¤±è´¥ï¼Œè·³è¿‡
#
#         landmarks = np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(68)])
#
#         # 4. çœ¼ç›é—­åˆæ£€æµ‹
#         left_eye = landmarks[36:42]
#         right_eye = landmarks[42:48]
#         ear_left = eye_aspect_ratio(left_eye)
#         ear_right = eye_aspect_ratio(right_eye)
#
#         if ear_left < eye_aspect_ratio_threshold and ear_right < eye_aspect_ratio_threshold:
#             removal_reasons["çœ¼ç›é—­åˆ"] += 1
#             continue  # çœ¼ç›é—­åˆï¼Œè·³è¿‡
#
#         # 5. è®¡ç®—å¤´éƒ¨åç§»è§’åº¦
#         yaw, pitch = face_orientation(landmarks)
#         if yaw > yaw_threshold or pitch > pitch_threshold:
#             removal_reasons["å¤´éƒ¨åç§»è¿‡å¤§"] += 1
#             continue  # å¤´éƒ¨è§’åº¦ä¸åˆé€‚ï¼Œè·³è¿‡
#
#         face_ok = True
#         break  # åªè¦æœ‰ä¸€ä¸ªåˆæ ¼çš„äººè„¸ï¼Œå°±ä¿ç•™
#
#     if face_ok:
#         best_image = best_images[prefix]
#
#         if best_image is not None:
#             similarity = compare_images(best_image, image)
#             if similarity > similarity_threshold:
#                 removal_reasons["é‡å¤ç…§ç‰‡"] += 1
#                 removed_images += 1
#                 continue  # å¦‚æœç›¸ä¼¼åº¦é«˜äºé˜ˆå€¼ï¼Œåˆ™è·³è¿‡
#
#         # ä¿å­˜å½“å‰å›¾ç‰‡
#         cv2.imwrite(os.path.join(output_folder, filename), image)
#         kept_images += 1
#         best_images[prefix] = image
#
# # ç»Ÿè®¡ç»“æœ
# print(f"ğŸ“· æ€»å…±å¤„ç†å›¾ç‰‡: {total_images}")
# print(f"âœ… ä¿ç•™å›¾ç‰‡: {kept_images}")
# print(f"âŒ å»é™¤å›¾ç‰‡: {removed_images}")
# print("å»é™¤åŸå› ç»Ÿè®¡:", dict(removal_reasons))







# import cv2
# import dlib
# import numpy as np
# import os
# from scipy.spatial import distance as dist
# from scipy.spatial.transform import Rotation as R
# from skimage.metrics import structural_similarity as ssim
#
# # ç›®å½•è®¾ç½®
# input_folder = "H:/fenjie/finspt"   # è¾“å…¥æ–‡ä»¶å¤¹
# output_folder = "H:/fenjie/tp"  # è¾“å‡ºæ–‡ä»¶å¤¹
# os.makedirs(output_folder, exist_ok=True)
#
# # åŠ è½½ Dlib äººè„¸æ£€æµ‹å™¨ & 68 å…³é”®ç‚¹é¢„æµ‹å™¨
# detector = dlib.get_frontal_face_detector()
# predictor = dlib.shape_predictor("E:/ai/fenjie/shape_predictor_68_face_landmarks.dat")
#   # ç¡®ä¿è¿™ä¸ªæ¨¡å‹æ–‡ä»¶å­˜åœ¨
#
# # è®¾ç½®å‚æ•°
# blur_threshold = 100  # æ¸…æ™°åº¦é˜ˆå€¼ï¼ˆè¶Šé«˜è¶Šä¸¥æ ¼ï¼‰
# yaw_threshold = 100     # å·¦å³åå¤´æœ€å¤§è§’åº¦
# pitch_threshold = 100   # ä¸Šä¸‹ä¿¯ä»°æœ€å¤§è§’åº¦
# eye_aspect_ratio_threshold = 0.3  # çœ¼ç›é—­åˆé˜ˆå€¼ï¼Œæ”¹ä¸º 0.25 æ›´ä¸¥æ ¼ï¼Œæ”¹ä¸º 0.15 æ›´å®½æ¾ã€‚
# similarity_threshold = 0.8  # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0.8ä»¥ä¸Šè®¤ä¸ºæ˜¯é‡å¤çš„ç…§ç‰‡è¶Šä½è¶Šä¸¥æ ¼ï¼Œè¶Šé«˜è¶Šå®½æ¾ï¼‰
#
# # åˆå§‹åŒ–å˜é‡
# total_images = 0
# kept_images = 0
# removed_images = 0
# best_image = None
# best_image_ssim = -1  # åˆå§‹æœ€å¥½çš„ç›¸ä¼¼åº¦ä¸º -1
#
# def calculate_blur(image):
#     """ è®¡ç®—å›¾åƒçš„æ¸…æ™°åº¦ï¼ˆLaplacian æ¨¡ç³Šåº¦ï¼‰"""
#     return cv2.Laplacian(image, cv2.CV_64F).var()
#
# def eye_aspect_ratio(eye):
#     """ è®¡ç®—çœ¼ç›çºµæ¨ªæ¯”ï¼ˆEARï¼‰ï¼Œç”¨äºæ£€æµ‹é—­çœ¼ """
#     A = dist.euclidean(eye[1], eye[5])
#     B = dist.euclidean(eye[2], eye[4])
#     C = dist.euclidean(eye[0], eye[3])
#     return (A + B) / (2.0 * C)
#
# def is_face_angle_valid(landmarks):
#     """ åˆ¤æ–­äººè„¸è§’åº¦æ˜¯å¦ç¬¦åˆè¦æ±‚ """
#     nose = landmarks[30]    # é¼»å°–
#     left_eye = landmarks[36]  # å·¦çœ¼è§’
#     right_eye = landmarks[45]  # å³çœ¼è§’
#     chin = landmarks[8]      # ä¸‹å·´
#
#     # è®¡ç®— Yawï¼ˆå·¦å³åå¤´è§’åº¦ï¼‰
#     delta_x = right_eye[0] - left_eye[0]
#     delta_y = right_eye[1] - left_eye[1]
#     yaw = np.degrees(np.arctan2(delta_y, delta_x))
#
#     # è®¡ç®— Pitchï¼ˆä¸Šä¸‹ä½å¤´ä»°å¤´è§’åº¦ï¼‰
#     delta_nose = nose[1] - chin[1]
#     delta_eyes = np.linalg.norm(right_eye - left_eye)
#     pitch = np.degrees(np.arctan2(delta_nose, delta_eyes))
#
#     return abs(yaw) <= yaw_threshold and abs(pitch) <= pitch_threshold
#
# def compare_images(image1, image2):
#     """ æ¯”è¾ƒä¸¤å¼ å›¾ç‰‡çš„ç›¸ä¼¼åº¦ï¼Œä½¿ç”¨ SSIM """
#     gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)
#     gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)
#     score, _ = ssim(gray1, gray2, full=True)
#     return score
#
# # å¤„ç†æ¯å¼ å›¾ç‰‡
# for filename in os.listdir(input_folder):
#     img_path = os.path.join(input_folder, filename)
#     image = cv2.imread(img_path)
#
#     if image is None:
#         continue
#
#     total_images += 1
#
#     # è½¬æ¢ä¸ºç°åº¦å›¾
#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
#
#     # 1. æ¸…æ™°åº¦æ£€æµ‹
#     blur_value = calculate_blur(gray)
#     if blur_value < blur_threshold:
#         removed_images += 1
#         continue  # è¿‡äºæ¨¡ç³Šï¼Œè·³è¿‡
#
#     # 2. äººè„¸æ£€æµ‹
#     faces = detector(gray)
#     if len(faces) == 0:
#         removed_images += 1
#         continue  # æ²¡æ£€æµ‹åˆ°äººè„¸ï¼Œè·³è¿‡
#
#     # 3. éå†æ‰€æœ‰æ£€æµ‹åˆ°çš„äººè„¸
#     face_ok = False
#     for face in faces:
#         landmarks = predictor(gray, face)
#         landmarks = np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(68)])
#
#         # 4. çœ¼ç›é—­åˆæ£€æµ‹
#         left_eye = landmarks[36:42]
#         right_eye = landmarks[42:48]
#         ear_left = eye_aspect_ratio(left_eye)
#         ear_right = eye_aspect_ratio(right_eye)
#
#         if ear_left < eye_aspect_ratio_threshold and ear_right < eye_aspect_ratio_threshold:
#             continue  # çœ¼ç›é—­åˆï¼Œè·³è¿‡
#
#         # 5. å¤´éƒ¨è§’åº¦æ£€æµ‹
#         if not is_face_angle_valid(landmarks):
#             continue  # å¤´éƒ¨è§’åº¦ä¸ç¬¦åˆè¦æ±‚ï¼Œè·³è¿‡
#
#         face_ok = True
#         break  # åªè¦æœ‰ä¸€ä¸ªåˆæ ¼çš„äººè„¸ï¼Œå°±ä¿ç•™
#
#     if face_ok:
#         # å¦‚æœæœ‰â€œæœ€å¥½çš„å›¾ç‰‡â€ï¼Œè®¡ç®—ç›¸ä¼¼åº¦
#         if best_image is not None:
#             similarity = compare_images(best_image, image)
#             if similarity > similarity_threshold:
#                 removed_images += 1
#                 continue  # å¦‚æœç›¸ä¼¼åº¦é«˜äºé˜ˆå€¼ï¼Œåˆ™è·³è¿‡
#         else:
#             similarity = -1  # ç¬¬ä¸€æ¬¡æ²¡æœ‰ç›¸ä¼¼åº¦å€¼
#
#         # ä¿å­˜å½“å‰å›¾ç‰‡
#         cv2.imwrite(os.path.join(output_folder, filename), image)
#         kept_images += 1
#
#         # æ›´æ–°â€œæœ€å¥½çš„å›¾ç‰‡â€åŠç›¸ä¼¼åº¦
#         best_image = image
#         best_image_ssim = similarity if best_image is not None else -1
#     else:
#         removed_images += 1
#
# # ç»Ÿè®¡ç»“æœ
# print(f"ğŸ“· æ€»å…±å¤„ç†å›¾ç‰‡: {total_images}")
# print(f"âœ… ä¿ç•™å›¾ç‰‡: {kept_images}")
# print(f"âŒ å»é™¤å›¾ç‰‡: {removed_images}")
